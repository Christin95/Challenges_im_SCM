{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy import spatial\n",
    "from numpy import nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ChristinScheib/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load medium library english for spaCy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# download Vader for nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/ChristinScheib/Documents/Sommersemester_2021/Challenges_SCM/C-SCM-DATA-Candidates_Evaluation_Anonymized_SS21.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(path, engine='openpyxl')\n",
    "data_ = data[['Person ID','Evaluation Statement']]\n",
    "\n",
    "statements = []\n",
    "for index, row in data_.iterrows():\n",
    "    statements.append((row['Person ID'], row['Evaluation Statement']))\n",
    "\n",
    "statements_clean = [i for i in statements if nan not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative = ['creative', 'constructive', 'resourceful', 'imaginative', 'ingenious', 'canny', 'inventive', 'full of ideas', 'clever', 'adventurous', 'innovative', 'originative', 'visionary', 'fanciful', 'forward thinker', 'pioneering', 'fertile', 'mastermind', 'genius', 'go-ahead', 'witty', 'eccentrically', 'inspiring', 'stimulating', 'encouraging', 'rich in ideas', 'inspirational']\n",
    "open_ = ['open','outgoing', 'curious', 'open-minded', 'broad-minded', 'honest', 'empathetic', 'respectful', 'positivity', 'emotional intelleligence', 'interest', 'interested', 'adapting' , 'informative', 'sharing', 'feedback', 'honesty', 'trust', 'valuing', 'diversity', 'perspective']\n",
    "responsible = ['responsible','decisions', 'decision-maker', 'supportive', 'prepared', 'proactive', 'reliable', 'trustworthy', 'discipline', 'respectable', 'committed', 'integrity', 'pushing', 'assertive', 'obligated', 'judicious' , 'organized', 'managing', 'consistent']\n",
    "entrepreneurial = ['entrepreneurial', 'enterprising', 'entrepreneurially', 'profit-oriented', 'for-profit', 'profit-seeking', 'need for achievement', \"self-efficacy\", 'innovativeness', 'stress tolerant', 'need for autonomy', 'proactive', 'disruptive', 'personality', 'venturesome', 'prepared to take risks', 'visionary', 'goal-oriented', 'purposeful', 'active', 'engaged', 'maker', 'doer', 'self-starter', 'calm', 'passionate', 'positive', 'convinced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    \n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "     \n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "105\n",
      "110\n",
      "115\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "160\n",
      "165\n",
      "170\n",
      "175\n",
      "180\n",
      "185\n",
      "190\n",
      "195\n",
      "200\n",
      "205\n",
      "210\n",
      "215\n",
      "220\n",
      "225\n",
      "230\n",
      "235\n",
      "240\n",
      "245\n",
      "250\n",
      "255\n",
      "260\n",
      "265\n",
      "270\n",
      "275\n",
      "280\n",
      "285\n",
      "290\n",
      "295\n",
      "300\n",
      "305\n",
      "310\n",
      "315\n",
      "320\n",
      "325\n",
      "330\n",
      "335\n",
      "340\n",
      "345\n",
      "350\n",
      "355\n",
      "360\n",
      "365\n",
      "370\n",
      "375\n",
      "380\n",
      "385\n",
      "390\n",
      "395\n",
      "400\n",
      "405\n",
      "410\n",
      "415\n",
      "420\n",
      "425\n",
      "430\n",
      "435\n",
      "440\n",
      "445\n",
      "450\n",
      "455\n",
      "460\n",
      "465\n",
      "470\n",
      "475\n",
      "480\n",
      "485\n",
      "490\n",
      "495\n",
      "500\n",
      "505\n",
      "510\n",
      "515\n",
      "520\n",
      "525\n",
      "530\n",
      "535\n",
      "540\n",
      "545\n",
      "550\n",
      "555\n",
      "560\n",
      "565\n",
      "570\n",
      "575\n",
      "580\n",
      "585\n",
      "590\n",
      "595\n",
      "600\n",
      "605\n",
      "610\n",
      "615\n",
      "620\n",
      "625\n",
      "630\n",
      "635\n",
      "640\n",
      "645\n",
      "650\n",
      "655\n",
      "660\n",
      "665\n",
      "670\n",
      "675\n",
      "680\n",
      "685\n",
      "690\n",
      "695\n",
      "700\n",
      "705\n",
      "710\n",
      "715\n",
      "720\n",
      "725\n",
      "730\n",
      "735\n",
      "740\n",
      "745\n",
      "750\n",
      "755\n",
      "760\n",
      "765\n",
      "770\n",
      "775\n",
      "780\n",
      "785\n",
      "790\n",
      "795\n",
      "800\n",
      "805\n",
      "810\n",
      "815\n",
      "820\n",
      "825\n",
      "830\n",
      "835\n",
      "840\n",
      "845\n",
      "850\n",
      "855\n",
      "860\n",
      "865\n",
      "870\n",
      "875\n",
      "880\n",
      "885\n",
      "890\n",
      "895\n",
      "900\n",
      "905\n",
      "910\n",
      "915\n",
      "920\n",
      "925\n",
      "930\n",
      "935\n",
      "940\n",
      "945\n",
      "950\n",
      "955\n",
      "960\n",
      "965\n",
      "970\n",
      "975\n",
      "980\n",
      "985\n",
      "990\n",
      "995\n",
      "1000\n",
      "1005\n",
      "1010\n",
      "1015\n",
      "1020\n",
      "1025\n",
      "1030\n",
      "1035\n",
      "1040\n",
      "1045\n",
      "1050\n",
      "1055\n",
      "1060\n",
      "1065\n",
      "1070\n",
      "1075\n",
      "1080\n",
      "1085\n",
      "1090\n",
      "1095\n",
      "1100\n",
      "1105\n",
      "1110\n",
      "1115\n",
      "1120\n",
      "1125\n",
      "1130\n",
      "1135\n",
      "1140\n",
      "1145\n",
      "1150\n",
      "1155\n",
      "1160\n",
      "1165\n",
      "1170\n",
      "1175\n",
      "1180\n",
      "1185\n",
      "1190\n",
      "1195\n",
      "1200\n",
      "1205\n",
      "1210\n",
      "1215\n",
      "1220\n",
      "1225\n",
      "1230\n",
      "1235\n",
      "1240\n",
      "1245\n",
      "1250\n",
      "1255\n",
      "1260\n",
      "1265\n",
      "1270\n",
      "1275\n",
      "1280\n",
      "1285\n",
      "1290\n",
      "1295\n",
      "1300\n",
      "1305\n",
      "1310\n",
      "1315\n",
      "1320\n",
      "1325\n",
      "1330\n",
      "1335\n",
      "1340\n",
      "1345\n",
      "1350\n",
      "1355\n",
      "1360\n",
      "1365\n",
      "1370\n",
      "1375\n",
      "1380\n",
      "1385\n",
      "1390\n",
      "1395\n",
      "1400\n",
      "1405\n",
      "1410\n",
      "1415\n",
      "1420\n",
      "1425\n",
      "1430\n",
      "1435\n",
      "1440\n",
      "1445\n",
      "1450\n",
      "1455\n",
      "1460\n",
      "1465\n",
      "1470\n",
      "1475\n",
      "1480\n",
      "1485\n",
      "1490\n",
      "1495\n",
      "1500\n",
      "1505\n",
      "1510\n",
      "1515\n",
      "1520\n",
      "1525\n",
      "1530\n",
      "1535\n",
      "1540\n",
      "1545\n",
      "1550\n",
      "1555\n",
      "1560\n",
      "1565\n",
      "1570\n",
      "1575\n",
      "1580\n",
      "1585\n",
      "1590\n",
      "1595\n",
      "1600\n",
      "1605\n",
      "1610\n",
      "1615\n",
      "1620\n",
      "1625\n",
      "1630\n",
      "1635\n",
      "1640\n"
     ]
    }
   ],
   "source": [
    "_POS = {\"ADJ\"}\n",
    "\n",
    "language_model = \"en_core_web_lg\"\n",
    "nlp = spacy.load(language_model)\n",
    "\n",
    "dict_ = {}\n",
    "index = 0\n",
    "for id_,s in statements_clean:\n",
    "    adj_nouns = []\n",
    "    if len(s) != 0:\n",
    "        for sent in nlp(s).sents:\n",
    "            for t in sent.as_doc():\n",
    "                if(t.pos_ in _POS):\n",
    "                    adj_nouns.append((t, sent, id_))\n",
    "\n",
    "            for noun in sent.noun_chunks:\n",
    "                adj_nouns.append((noun, sent, id_))        \n",
    "\n",
    "        threshold = 0.725\n",
    "\n",
    "        set_creative = set()\n",
    "        set_open = set()\n",
    "        set_responsible = set()\n",
    "        set_entr = set()\n",
    "\n",
    "        for i, sent, id_ in adj_nouns:\n",
    "            for c in creative:\n",
    "                sim = cosine_similarity(i.vector,nlp(c).vector)\n",
    "                if(sim >= threshold):\n",
    "                    set_creative.add(sent)\n",
    "            for o in open_:\n",
    "                sim = cosine_similarity(i.vector,nlp(o).vector)\n",
    "                if(sim >= threshold):\n",
    "                    set_open.add(sent)\n",
    "            for r in responsible:\n",
    "                sim = cosine_similarity(i.vector,nlp(r).vector)\n",
    "                if(sim >= threshold):\n",
    "                    set_responsible.add(sent)\n",
    "            for e in entrepreneurial:\n",
    "                sim = cosine_similarity(i.vector,nlp(e).vector)\n",
    "                if(sim >= threshold):\n",
    "                    set_entr.add(sent)\n",
    "\n",
    "        ls_compound_creative = []\n",
    "        if not set_creative:\n",
    "            ls_compound_creative.append(0)\n",
    "        else:\n",
    "            for s in set_creative:\n",
    "                ls_compound_creative.append(sentiment_scores(s.text))\n",
    "\n",
    "        ls_compound_open = []\n",
    "        if not set_open:\n",
    "            ls_compound_open.append(0)\n",
    "        else:\n",
    "            for s in set_open:\n",
    "                ls_compound_open.append(sentiment_scores(s.text))\n",
    "\n",
    "        ls_compound_responsible = []\n",
    "        if not set_responsible:\n",
    "            ls_compound_responsible.append(0)\n",
    "        else:\n",
    "            for s in set_responsible:\n",
    "                ls_compound_responsible.append(sentiment_scores(s.text))\n",
    "\n",
    "        ls_compound_entr = []\n",
    "        if not set_entr:\n",
    "            ls_compound_entr.append(0)\n",
    "        else:\n",
    "            for s in set_entr:\n",
    "                ls_compound_entr.append(sentiment_scores(s.text))\n",
    "\n",
    "        dict_[id_] = {\"creative\": statistics.mean(ls_compound_creative), \n",
    "                      \"open\":statistics.mean(ls_compound_open) , \n",
    "                      \"responsible\": statistics.mean(ls_compound_responsible), \n",
    "                      \"entrepreneurial\":statistics.mean(ls_compound_entr)\n",
    "                     }   \n",
    "\n",
    "        if index % 5 == 0:\n",
    "            print(index)\n",
    "      #      break\n",
    "        index = index + 1\n",
    "    else: \n",
    "        dict_[id_] = {\"creative\": 0, \n",
    "                      \"open\": 0 , \n",
    "                      \"responsible\": 0, \n",
    "                      \"entrepreneurial\":0\n",
    "                     }\n",
    "        index = index + 1\n",
    "        \n",
    "    #print(dict_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          creative     open  responsible  entrepreneurial\n",
      "580346.0  0.000000  0.62980      0.27160         0.419867\n",
      "586882.0  0.831600  0.77830      0.00000         0.768367\n",
      "574743.0  0.630067  0.61025      0.52895         0.724900\n",
      "360306.0  0.000000  0.05160      0.00000         0.750600\n",
      "790206.0  0.827333  0.00000      0.00000         0.000000\n",
      "...            ...      ...          ...              ...\n",
      "897173.0  0.000000  0.93180      0.93180         0.000000\n",
      "573479.0  0.000000  0.00000      0.00000         0.784500\n",
      "933345.0  0.612400  0.54230      0.53450         0.612400\n",
      "535989.0  0.670500  0.00000      0.27320         0.000000\n",
      "578781.0  0.401900  0.00000      0.68245         0.401900\n",
      "\n",
      "[1643 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=dict_)\n",
    "\n",
    "df = (df.T)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel('/Users/ChristinScheib/Documents/Sommersemester_2021/Challenges_SCM/CoreValues_Analyzed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scm",
   "language": "python",
   "name": "scm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
